{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9557725,"sourceType":"datasetVersion","datasetId":5824053}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-10-06T16:26:34.323435Z","iopub.execute_input":"2024-10-06T16:26:34.324147Z","iopub.status.idle":"2024-10-06T16:26:35.770518Z","shell.execute_reply.started":"2024-10-06T16:26:34.324100Z","shell.execute_reply":"2024-10-06T16:26:35.769566Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torchvision\nimport math\nimport matplotlib.pyplot as plt\nimport torch\nimport numpy as np\nimport PIL\nfrom PIL import Image\n\ndevice = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T06:08:14.388616Z","iopub.execute_input":"2024-10-11T06:08:14.389730Z","iopub.status.idle":"2024-10-11T06:08:19.280014Z","shell.execute_reply.started":"2024-10-11T06:08:14.389678Z","shell.execute_reply":"2024-10-11T06:08:19.278829Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image_pairs(raw_image_folder, ref_image_folder):\n    raw_images = []\n    ref_images = []\n    \n    for filename in os.listdir(raw_image_folder):\n        raw_image_path = os.path.join(raw_image_folder, filename)\n        ref_image_path = os.path.join(ref_image_folder, filename)\n        \n        if os.path.exists(ref_image_path):\n            raw_image = Image.open(raw_image_path)\n            ref_image = Image.open(ref_image_path)\n            \n            raw_images.append(raw_image)\n            ref_images.append(ref_image)\n    \n    return raw_images, ref_images\n\nraw_image_folder = '/kaggle/input/underwater4/Train/Raw'\nref_image_folder = '/kaggle/input/underwater4/Train/Raw'\nraw_images, ref_images = load_image_pairs(raw_image_folder, ref_image_folder)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T06:08:19.281995Z","iopub.execute_input":"2024-10-11T06:08:19.282451Z","iopub.status.idle":"2024-10-11T06:08:28.886080Z","shell.execute_reply.started":"2024-10-11T06:08:19.282413Z","shell.execute_reply":"2024-10-11T06:08:28.885133Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DiffusionModel:\n    def __init__(self, start_schedule=0.0001, end_schedule=0.02, timesteps=300):\n        self.start_schedule = start_schedule\n        self.end_schedule = end_schedule\n        self.timesteps = timesteps\n        self.betas = torch.linspace(start_schedule, end_schedule, timesteps)\n        self.alphas = 1 - self.betas\n        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n\n    def forward(self, x_0, t, device):\n        noise = torch.randn_like(x_0)\n        sqrt_alphas_cumprod_t = self.get_index_from_list(self.alphas_cumprod.sqrt(), t, x_0.shape)\n        sqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alphas_cumprod), t, x_0.shape)\n        mean = sqrt_alphas_cumprod_t.to(device) * x_0.to(device)\n        variance = sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device)\n        return mean + variance, noise.to(device)\n    \n    @torch.no_grad()\n    def backward(self, x, t, model, **kwargs):\n        betas_t = self.get_index_from_list(self.betas, t, x.shape)\n        sqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alphas_cumprod), t, x.shape)\n        sqrt_recip_alphas_t = self.get_index_from_list(torch.sqrt(1.0 / self.alphas), t, x.shape)\n        mean = sqrt_recip_alphas_t * (x - betas_t * model(x, t, **kwargs) / sqrt_one_minus_alphas_cumprod_t)\n        posterior_variance_t = betas_t\n\n        # Check if all timesteps are 0, otherwise generate noise\n        if t.eq(0).all():  # Ensuring it works for batch tensors\n            return mean\n        else:\n            noise = torch.randn_like(x)\n            variance = torch.sqrt(posterior_variance_t) * noise\n            return mean + variance\n\n\n    @staticmethod\n    def get_index_from_list(values, t, x_shape):\n        batch_size = t.shape[0]\n        result = values.gather(-1, t.cpu())\n        return result.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T06:08:28.887641Z","iopub.execute_input":"2024-10-11T06:08:28.888015Z","iopub.status.idle":"2024-10-11T06:08:28.902294Z","shell.execute_reply.started":"2024-10-11T06:08:28.887978Z","shell.execute_reply":"2024-10-11T06:08:28.901210Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SHAPE = (128, 128)\n\ntransform = transforms.Compose([\n    transforms.Resize(IMAGE_SHAPE), \n    transforms.ToTensor(), \n    transforms.Lambda(lambda t: (t * 2) - 1), \n])\n\nreverse_transform = transforms.Compose([\n    transforms.Lambda(lambda t: (t + 1) / 2), \n    transforms.Lambda(lambda t: t.permute(1, 2, 0)), \n    transforms.Lambda(lambda t: t * 255.), \n    transforms.Lambda(lambda t: t.cpu().numpy().astype(np.uint8)), \n    transforms.ToPILImage(), \n])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T06:08:28.904758Z","iopub.execute_input":"2024-10-11T06:08:28.905737Z","iopub.status.idle":"2024-10-11T06:08:28.913663Z","shell.execute_reply.started":"2024-10-11T06:08:28.905689Z","shell.execute_reply":"2024-10-11T06:08:28.912639Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SinusoidalPositionEmbeddings(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, time):\n        device = time.device\n        half_dim = self.dim // 2\n        embeddings = math.log(10000) / (half_dim - 1)\n        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n        embeddings = time[:, None] * embeddings[None, :]\n        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n        return embeddings\n\nclass Block(nn.Module):\n    def __init__(self, channels_in, channels_out, time_embedding_dims, num_filters=3, downsample=True):\n        super().__init__()\n        self.time_embedding = SinusoidalPositionEmbeddings(time_embedding_dims)\n        self.downsample = downsample\n        \n        if downsample:\n            self.conv1 = nn.Conv2d(channels_in, channels_out, num_filters, padding=1)\n            self.final = nn.Conv2d(channels_out, channels_out, 4, 2, 1)\n        else:\n            self.conv1 = nn.Conv2d(2 * channels_in, channels_out, num_filters, padding=1)\n            self.final = nn.ConvTranspose2d(channels_out, channels_out, 4, 2, 1)\n        \n        self.bnorm1 = nn.BatchNorm2d(channels_out)\n        self.bnorm2 = nn.BatchNorm2d(channels_out)\n        self.conv2 = nn.Conv2d(channels_out, channels_out, 3, padding=1)\n        self.time_mlp = nn.Linear(time_embedding_dims, channels_out)\n        self.relu = nn.ReLU()\n\n    def forward(self, x, t):\n        o = self.bnorm1(self.relu(self.conv1(x)))\n        o_time = self.relu(self.time_mlp(self.time_embedding(t)))\n        o = o + o_time[..., None, None]\n        o = self.bnorm2(self.relu(self.conv2(o)))\n        return self.final(o)\n\n\nclass UNet(nn.Module):\n    def __init__(self, img_channels=3, time_embedding_dims=128, sequence_channels=(64, 128, 256, 512)):\n        super().__init__()\n        self.downsampling = nn.ModuleList([Block(ch_in, ch_out, time_embedding_dims) for ch_in, ch_out in zip(sequence_channels, sequence_channels[1:])])\n        self.upsampling = nn.ModuleList([Block(ch_in, ch_out, time_embedding_dims, downsample=False) for ch_in, ch_out in zip(sequence_channels[::-1], sequence_channels[::-1][1:])])\n        self.conv1 = nn.Conv2d(img_channels, sequence_channels[0], 3, padding=1)\n        self.conv2 = nn.Conv2d(sequence_channels[0], img_channels, 1)\n\n    def forward(self, x, t):\n        residuals = []\n        o = self.conv1(x)\n        for ds in self.downsampling:\n            o = ds(o, t)\n            residuals.append(o)\n        for us, res in zip(self.upsampling, reversed(residuals)):\n            o = us(torch.cat((o, res), dim=1), t)\n        return self.conv2(o)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T06:09:18.600626Z","iopub.execute_input":"2024-10-11T06:09:18.601491Z","iopub.status.idle":"2024-10-11T06:09:18.623017Z","shell.execute_reply.started":"2024-10-11T06:09:18.601432Z","shell.execute_reply":"2024-10-11T06:09:18.621951Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_noise_distribution(noise, predicted_noise):\n    plt.hist(noise.cpu().detach().numpy().flatten(), density=True, alpha=0.8, label=\"ground truth noise\")\n    plt.hist(predicted_noise.cpu().detach().numpy().flatten(), density=True, alpha=0.8, label=\"predicted noise\")\n    plt.legend()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T06:09:22.239383Z","iopub.execute_input":"2024-10-11T06:09:22.239858Z","iopub.status.idle":"2024-10-11T06:09:22.246314Z","shell.execute_reply.started":"2024-10-11T06:09:22.239787Z","shell.execute_reply":"2024-10-11T06:09:22.245276Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_noise_prediction(noise, predicted_noise):\n    plt.figure(figsize=(15, 15))\n    f, ax = plt.subplots(1, 2, figsize=(5, 5))\n    ax[0].imshow(reverse_transform(noise.detach()))\n    ax[0].set_title(\"ground truth noise\", fontsize=10)\n    ax[1].imshow(reverse_transform(predicted_noise.detach()))\n    ax[1].set_title(\"predicted noise\", fontsize=10)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T06:09:23.733389Z","iopub.execute_input":"2024-10-11T06:09:23.733849Z","iopub.status.idle":"2024-10-11T06:09:23.741327Z","shell.execute_reply.started":"2024-10-11T06:09:23.733778Z","shell.execute_reply":"2024-10-11T06:09:23.740171Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\nNO_EPOCHS = 2000\nPRINT_FREQUENCY = 50\nLR = 0.001\nBATCH_SIZE = 16\n\nunet = UNet().to(device)\noptimizer = torch.optim.Adam(unet.parameters(), lr=LR)\n\ndiffusion_model = DiffusionModel()\n\nfor epoch in range(NO_EPOCHS):\n    mean_epoch_loss = []\n    \n    # Shuffle the raw images at the start of each epoch\n    shuffled_indices = list(range(len(raw_images)))\n    random.shuffle(shuffled_indices)\n    \n    # Selecting a random batch from shuffled images\n    batch_raw_images = [transform(raw_images[i]).unsqueeze(0) for i in shuffled_indices[:BATCH_SIZE]]\n    batch_ref_images = [ref_images[i] for i in shuffled_indices[:BATCH_SIZE]]\n    \n    batch_raw_images = torch.cat(batch_raw_images).to(device)\n\n    optimizer.zero_grad()\n    \n    t = torch.randint(0, diffusion_model.timesteps, (BATCH_SIZE,), device=device).long()\n    x_t, noise = diffusion_model.forward(batch_raw_images, t, device)\n    \n    noise_pred = unet(x_t, t)\n    loss = nn.MSELoss()(noise_pred, noise)\n    \n    loss.backward()\n    optimizer.step()\n    \n    mean_epoch_loss.append(loss.item())\n    \n    if (epoch % PRINT_FREQUENCY == 0):\n        print(f\"Epoch {epoch} | Loss: {np.mean(mean_epoch_loss)}\")\n\n        denoised_images = diffusion_model.backward(x_t, t, unet)\n        \n        for i in range(3):  # Show 3 images\n            # Plot raw image, reference image, and denoised image\n            plt.figure(figsize=(15, 15))\n            f, ax = plt.subplots(1, 3, figsize=(15, 15))\n            \n            ax[0].imshow(reverse_transform(batch_raw_images[i].detach()))\n            ax[0].set_title(f\"Raw Image (Epoch {epoch})\", fontsize=10)\n            \n            ax[1].imshow(batch_ref_images[i])\n            ax[1].set_title(f\"Reference Image\", fontsize=10)\n            \n            ax[2].imshow(reverse_transform(denoised_images[i].detach()))\n            ax[2].set_title(f\"Denoised Image (Epoch {epoch})\", fontsize=10)\n            \n            plt.show()\n\n        # Plot noise distribution and prediction\n        plot_noise_distribution(noise, noise_pred)\n        plot_noise_prediction(noise[0], noise_pred[0])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-11T06:09:27.636272Z","iopub.execute_input":"2024-10-11T06:09:27.636704Z","iopub.status.idle":"2024-10-11T06:24:50.890898Z","shell.execute_reply.started":"2024-10-11T06:09:27.636663Z","shell.execute_reply":"2024-10-11T06:24:50.889750Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add a perceptual loss function (you can use MSE here as a simple example)\ndef combined_loss(denoised_images, reference_images, noise_pred, noise, alpha=0.5):\n    # MSE loss between denoised images and reference images\n    mse_loss = nn.MSELoss()(denoised_images, reference_images)\n    # MSE loss between predicted noise and actual noise\n    noise_loss = nn.MSELoss()(noise_pred, noise)\n    # Combine losses\n    return alpha * mse_loss + (1 - alpha) * noise_loss\nimport random\n\nNO_EPOCHS = 2000\nPRINT_FREQUENCY = 50\nLR = 0.001\nBATCH_SIZE = 16\nunet = UNet().to(device)\noptimizer = torch.optim.Adam(unet.parameters(), lr=LR)\n\ndiffusion_model = DiffusionModel()\n# Training loop\nfor epoch in range(NO_EPOCHS):\n    mean_epoch_loss = []\n    \n    # Shuffle the raw images at the start of each epoch\n    shuffled_indices = list(range(len(raw_images)))\n    random.shuffle(shuffled_indices)\n    \n    # Selecting a random batch from shuffled images\n    batch_raw_images = [transform(raw_images[i]).unsqueeze(0) for i in shuffled_indices[:BATCH_SIZE]]\n    batch_ref_images = [transform(ref_images[i]).unsqueeze(0) for i in shuffled_indices[:BATCH_SIZE]]\n    \n    batch_raw_images = torch.cat(batch_raw_images).to(device)\n    batch_ref_images = torch.cat(batch_ref_images).to(device)\n\n    optimizer.zero_grad()\n    \n    t = torch.randint(0, diffusion_model.timesteps, (BATCH_SIZE,), device=device).long()\n    x_t, noise = diffusion_model.forward(batch_raw_images, t, device)\n    \n    noise_pred = unet(x_t, t)\n    # Compute the combined loss\n    loss = combined_loss(diffusion_model.backward(x_t, t, unet), batch_ref_images, noise_pred, noise)\n\n    loss.backward()\n    optimizer.step()\n    \n    mean_epoch_loss.append(loss.item())\n    \n    if (epoch % PRINT_FREQUENCY == 0):\n        print(f\"Epoch {epoch} | Loss: {np.mean(mean_epoch_loss)}\")\n        \n        denoised_images = diffusion_model.backward(x_t, t, unet)\n        \n        for i in range(3):  # Show 3 images\n            # Plot raw image, reference image, and denoised image\n            plt.figure(figsize=(15, 15))\n            f, ax = plt.subplots(1, 3, figsize=(15, 15))\n            \n            ax[0].imshow(reverse_transform(batch_raw_images[i].detach()))\n            ax[0].set_title(f\"Raw Image (Epoch {epoch})\", fontsize=10)\n            \n            ax[1].imshow(reverse_transform(batch_ref_images[i].detach()))\n            ax[1].set_title(f\"Reference Image\", fontsize=10)\n            \n            ax[2].imshow(reverse_transform(denoised_images[i].detach()))\n            ax[2].set_title(f\"Denoised Image (Epoch {epoch})\", fontsize=10)\n            \n            plt.show()\n\n        # Plot noise distribution and prediction\n        plot_noise_distribution(noise, noise_pred)\n        plot_noise_prediction(noise[0], noise_pred[0])\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-11T06:28:05.756125Z","iopub.execute_input":"2024-10-11T06:28:05.756999Z","iopub.status.idle":"2024-10-11T06:48:49.316236Z","shell.execute_reply.started":"2024-10-11T06:28:05.756958Z","shell.execute_reply":"2024-10-11T06:48:49.315274Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.metrics import structural_similarity as ssim\nfrom PIL import Image  # Ensure to import Image\nimport torch.nn as nn  # Ensure nn is imported\n\n# Save the trained model\nmodel_save_path = 'diffusion_model.pth'\ntorch.save(unet.state_dict(), model_save_path)\nprint(f'Model saved to {model_save_path}')\n\n# Load images for testing\ndef load_test_image_pairs(raw_image_folder, ref_image_folder):\n    raw_images = []\n    ref_images = []\n    \n    for filename in os.listdir(raw_image_folder):\n        raw_image_path = os.path.join(raw_image_folder, filename)\n        ref_image_path = os.path.join(ref_image_folder, filename)\n        \n        if os.path.exists(ref_image_path):\n            raw_image = Image.open(raw_image_path).convert('RGB')  # Convert to RGB if not already\n            ref_image = Image.open(ref_image_path).convert('RGB')\n            \n            raw_images.append(raw_image)\n            ref_images.append(ref_image)\n    \n    return raw_images, ref_images\n\n# Define PSNR function\ndef psnr(denoised_image, ref_image):\n    mse_value = nn.MSELoss()(denoised_image, ref_image).item()\n    if mse_value == 0:\n        return float('inf')  # If MSE is 0, PSNR is infinite\n    max_pixel = 1.0  # Since the images are normalized to [-1, 1]\n    psnr_value = 20 * torch.log10(max_pixel / torch.sqrt(torch.tensor(mse_value)))\n    return psnr_value.item()\n\n# Load your test dataset\ntest_raw_folder = '/kaggle/input/underwater4/Test/Raw'  # Update with your test raw images path\ntest_ref_folder = '/kaggle/input/underwater4/Test/Reference'  # Update with your test reference images path\ntest_raw_images, test_ref_images = load_test_image_pairs(test_raw_folder, test_ref_folder)\n\n# Transform the test images\ntest_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SHAPE),\n    transforms.ToTensor(),\n    transforms.Lambda(lambda t: (t * 2) - 1),  # Normalize to [-1, 1]\n])\n\n# Initialize metrics lists\nmse_values = []\npsnr_values = []\nssim_values = []\n\n# Evaluate the model on test images\nunet.eval()  # Set model to evaluation mode\n\n# Testing loop\nfor i in range(len(test_raw_images)):\n    # Preprocess the raw image\n    raw_image = test_transform(test_raw_images[i]).unsqueeze(0).to(device)\n    ref_image = test_transform(test_ref_images[i]).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        denoised_image = unet(raw_image, torch.tensor([0], device=device))  # You can set a fixed timestep here\n\n    # Compute metrics\n    mse_value = nn.MSELoss()(denoised_image, ref_image).item()\n    mse_values.append(mse_value)\n\n    psnr_value = psnr(denoised_image, ref_image)\n    psnr_values.append(psnr_value)\n\n    # Update SSIM calculation\n    ssim_value = ssim(\n        denoised_image.squeeze(0).cpu().numpy().transpose(1, 2, 0), \n        ref_image.squeeze(0).cpu().numpy().transpose(1, 2, 0), \n        multichannel=True,\n        win_size=3,  # Set the window size to 3\n        data_range=2  # Set the data range for normalized images\n    )\n    ssim_values.append(ssim_value)\n\n    # Reverse the transformation for visualization\n    denoised_image_np = reverse_transform(denoised_image.squeeze(0).cpu())\n    ref_image_np = reverse_transform(ref_image.squeeze(0).cpu())\n\n    # Display results\n    plt.figure(figsize=(15, 15))\n    plt.subplot(1, 3, 1)\n    plt.imshow(reverse_transform(raw_image.squeeze(0).cpu()))\n    plt.title(\"Raw Image\")\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(ref_image_np)\n    plt.title(\"Reference Image\")\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(denoised_image_np)\n    plt.title(\"Denoised Image\")\n    \n    plt.show()\n\n# Display average metrics\nprint(f\"Average MSE: {np.mean(mse_values):.4f}\")\nprint(f\"Average PSNR: {np.mean(psnr_values):.4f}\")\nprint(f\"Average SSIM: {np.mean(ssim_values):.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-11T06:58:34.519467Z","iopub.execute_input":"2024-10-11T06:58:34.519950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}